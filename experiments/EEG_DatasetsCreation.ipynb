{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f14ecb-949f-4040-9a6f-a37162a001c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f9a567a-57b5-4000-8058-6ed50e2deff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.datasets import DREAMERDataset, SEEDDataset, SEEDIVDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2dd7c3-b6a6-4cd7-89c1-d231db68241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torcheeg as teeg\n",
    "from torcheeg.datasets.constants.emotion_recognition.dreamer import DREAMER_ADJACENCY_MATRIX, DREAMER_CHANNEL_LOCATION_DICT\n",
    "from torcheeg.datasets.constants.emotion_recognition.seed import SEED_ADJACENCY_MATRIX, SEED_CHANNEL_LOCATION_DICT\n",
    "from torcheeg.datasets.constants.emotion_recognition.seed_iv import SEED_IV_ADJACENCY_MATRIX, SEED_IV_CHANNEL_LOCATION_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b089c34-4e6f-4343-995a-9ef4ddd0d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg import transforms\n",
    "from torcheeg.transforms.pyg import ToG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd874e11-a6c2-4bd4-a668-85b2e54a0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\"..\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe527a-6e13-4cd8-9690-4bd9531565e0",
   "metadata": {},
   "source": [
    "## Placements and adjacency of electrodes\n",
    "\n",
    "Pretty usefull placement of the electrodes in any dataset of ours is [here (torcheeg)](https://github.com/torcheeg/torcheeg/tree/main/torcheeg/datasets/constants/emotion_recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6780922f-58a0-41a5-80f6-c92f534bd4e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DREAMER_ADJACENCY_MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300d5cd8-435d-4a3e-81fe-c71941ddd646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AF3': [1, 3],\n",
       " 'F7': [2, 0],\n",
       " 'F3': [2, 2],\n",
       " 'FC5': [3, 1],\n",
       " 'T7': [4, 0],\n",
       " 'P7': [6, 0],\n",
       " 'O1': [8, 3],\n",
       " 'O2': [8, 5],\n",
       " 'P8': [6, 8],\n",
       " 'T8': [4, 8],\n",
       " 'FC6': [3, 7],\n",
       " 'F4': [2, 6],\n",
       " 'F8': [2, 8],\n",
       " 'AF4': [1, 5]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DREAMER_CHANNEL_LOCATION_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5823f97b-5cb1-41f9-8df0-3f78003beff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 62)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(SEED_ADJACENCY_MATRIX).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42bdb9fc-f892-47b5-be89-326b98f3e44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FP1': [0, 3],\n",
       " 'FPZ': [0, 4],\n",
       " 'FP2': [0, 5],\n",
       " 'AF3': [1, 3],\n",
       " 'AF4': [1, 5],\n",
       " 'F7': [2, 0],\n",
       " 'F5': [2, 1],\n",
       " 'F3': [2, 2],\n",
       " 'F1': [2, 3],\n",
       " 'FZ': [2, 4],\n",
       " 'F2': [2, 5],\n",
       " 'F4': [2, 6],\n",
       " 'F6': [2, 7],\n",
       " 'F8': [2, 8],\n",
       " 'FT7': [3, 0],\n",
       " 'FC5': [3, 1],\n",
       " 'FC3': [3, 2],\n",
       " 'FC1': [3, 3],\n",
       " 'FCZ': [3, 4],\n",
       " 'FC2': [3, 5],\n",
       " 'FC4': [3, 6],\n",
       " 'FC6': [3, 7],\n",
       " 'FT8': [3, 8],\n",
       " 'T7': [4, 0],\n",
       " 'C5': [4, 1],\n",
       " 'C3': [4, 2],\n",
       " 'C1': [4, 3],\n",
       " 'CZ': [4, 4],\n",
       " 'C2': [4, 5],\n",
       " 'C4': [4, 6],\n",
       " 'C6': [4, 7],\n",
       " 'T8': [4, 8],\n",
       " 'TP7': [5, 0],\n",
       " 'CP5': [5, 1],\n",
       " 'CP3': [5, 2],\n",
       " 'CP1': [5, 3],\n",
       " 'CPZ': [5, 4],\n",
       " 'CP2': [5, 5],\n",
       " 'CP4': [5, 6],\n",
       " 'CP6': [5, 7],\n",
       " 'TP8': [5, 8],\n",
       " 'P7': [6, 0],\n",
       " 'P5': [6, 1],\n",
       " 'P3': [6, 2],\n",
       " 'P1': [6, 3],\n",
       " 'PZ': [6, 4],\n",
       " 'P2': [6, 5],\n",
       " 'P4': [6, 6],\n",
       " 'P6': [6, 7],\n",
       " 'P8': [6, 8],\n",
       " 'PO7': [7, 1],\n",
       " 'PO5': [7, 2],\n",
       " 'PO3': [7, 3],\n",
       " 'POZ': [7, 4],\n",
       " 'PO4': [7, 5],\n",
       " 'PO6': [7, 6],\n",
       " 'PO8': [7, 7],\n",
       " 'CB1': [8, 2],\n",
       " 'O1': [8, 3],\n",
       " 'OZ': [8, 4],\n",
       " 'O2': [8, 5],\n",
       " 'CB2': [8, 6]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED_CHANNEL_LOCATION_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e6aaa22-af9f-477d-b993-2f9e53b29683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 62)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(SEED_IV_ADJACENCY_MATRIX).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca672d4f-3b73-433c-b1bd-cd0face0aeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FP1': [0, 3],\n",
       " 'FPZ': [0, 4],\n",
       " 'FP2': [0, 5],\n",
       " 'AF3': [1, 3],\n",
       " 'AF4': [1, 5],\n",
       " 'F7': [2, 0],\n",
       " 'F5': [2, 1],\n",
       " 'F3': [2, 2],\n",
       " 'F1': [2, 3],\n",
       " 'FZ': [2, 4],\n",
       " 'F2': [2, 5],\n",
       " 'F4': [2, 6],\n",
       " 'F6': [2, 7],\n",
       " 'F8': [2, 8],\n",
       " 'FT7': [3, 0],\n",
       " 'FC5': [3, 1],\n",
       " 'FC3': [3, 2],\n",
       " 'FC1': [3, 3],\n",
       " 'FCZ': [3, 4],\n",
       " 'FC2': [3, 5],\n",
       " 'FC4': [3, 6],\n",
       " 'FC6': [3, 7],\n",
       " 'FT8': [3, 8],\n",
       " 'T7': [4, 0],\n",
       " 'C5': [4, 1],\n",
       " 'C3': [4, 2],\n",
       " 'C1': [4, 3],\n",
       " 'CZ': [4, 4],\n",
       " 'C2': [4, 5],\n",
       " 'C4': [4, 6],\n",
       " 'C6': [4, 7],\n",
       " 'T8': [4, 8],\n",
       " 'TP7': [5, 0],\n",
       " 'CP5': [5, 1],\n",
       " 'CP3': [5, 2],\n",
       " 'CP1': [5, 3],\n",
       " 'CPZ': [5, 4],\n",
       " 'CP2': [5, 5],\n",
       " 'CP4': [5, 6],\n",
       " 'CP6': [5, 7],\n",
       " 'TP8': [5, 8],\n",
       " 'P7': [6, 0],\n",
       " 'P5': [6, 1],\n",
       " 'P3': [6, 2],\n",
       " 'P1': [6, 3],\n",
       " 'PZ': [6, 4],\n",
       " 'P2': [6, 5],\n",
       " 'P4': [6, 6],\n",
       " 'P6': [6, 7],\n",
       " 'P8': [6, 8],\n",
       " 'PO7': [7, 1],\n",
       " 'PO5': [7, 2],\n",
       " 'PO3': [7, 3],\n",
       " 'POZ': [7, 4],\n",
       " 'PO4': [7, 5],\n",
       " 'PO6': [7, 6],\n",
       " 'PO8': [7, 7],\n",
       " 'CB1': [8, 2],\n",
       " 'O1': [8, 3],\n",
       " 'OZ': [8, 4],\n",
       " 'O2': [8, 5],\n",
       " 'CB2': [8, 6]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED_IV_CHANNEL_LOCATION_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1902116c-4670-442d-b4f6-9d88dbbeec52",
   "metadata": {},
   "source": [
    "# Simple preprocessing runs from torcheeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f68c73ef-8013-4425-be03-5f9cc595f994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset does not exist at path ..\\data\\dreamer, generating files to path...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[PROCESS]:   0%|                                                                                | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "[PROCESS]:  35%|█████████████████████████                                               | 8/23 [01:15<02:21,  9.44s/it]\u001b[A\n",
      "[PROCESS]:  52%|█████████████████████████████████████                                  | 12/23 [02:11<02:04, 11.33s/it]\u001b[A\n",
      "[PROCESS]:  70%|█████████████████████████████████████████████████▍                     | 16/23 [03:03<01:23, 11.95s/it]\u001b[A\n",
      "[PROCESS]: 100%|███████████████████████████████████████████████████████████████████████| 23/23 [03:55<00:00, 10.24s/it]\u001b[A\n",
      "\n",
      "[POST-PROCESS]:   0%|                                                                        | 0/85744 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Data(edge_index=[2, 46], x=[14, 128], edge_weight=[46]), 1)\n",
      "CPU times: total: 8.44 s\n",
      "Wall time: 6min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "dataset = DREAMERDataset(io_path=os.path.join(DATA_DIR, \"dreamer\"),\n",
    "                         mat_path=os.path.join(DATA_DIR, 'DREAMER.mat'),\n",
    "                         online_transform=transforms.Compose([\n",
    "                             ToG(DREAMER_ADJACENCY_MATRIX)\n",
    "                         ]),\n",
    "                         label_transform=transforms.Compose([\n",
    "                             transforms.Select('arousal'),\n",
    "                             transforms.Binary(3.0)\n",
    "                         ]),\n",
    "                         num_worker=4\n",
    "                        )\n",
    "print(dataset[0])\n",
    "# With the empty info it could take several minutes to preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca281ce-9a25-458b-bb5f-356bbc42fdaf",
   "metadata": {},
   "source": [
    "**Data** contains:\n",
    "- *edge_index* - Connectivity matrix of shape (2, n_edges)\n",
    "- *x* - tensor of signal, shape (n_channels, features_dim)\n",
    "- *edge_weight* -\n",
    "\n",
    "For the **DataBatch** there are added:\n",
    "- *pos* - Node position matrix with shape (n_nodes, num_dimensions)\n",
    "- *batch* is a column vector which maps each node to its respective graph in the batch\n",
    "\n",
    "For more examples, see [torch_geometric](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html?highlight=DataBatch#exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b930f483-2f04-410b-9365-6d2293a33096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset does not exist at path ..\\data\\seed, generating files to path...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[PROCESS]: 100%|███████████████████████████████████████████████████████████████████████| 45/45 [07:22<00:00,  9.84s/it]\n",
      "[POST-PROCESS]:   0%|                                                                       | 0/152730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Data(edge_index=[2, 281], x=[62, 200], edge_weight=[281]), 2)\n",
      "CPU times: total: 3.09 s\n",
      "Wall time: 8min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = SEEDDataset(io_path=os.path.join(DATA_DIR, \"seed\"),\n",
    "                      root_path=os.path.join(DATA_DIR, \"SEED_EEG\", 'Preprocessed_EEG'),\n",
    "                      online_transform=transforms.Compose([\n",
    "                          ToG(SEED_ADJACENCY_MATRIX)\n",
    "                      ]),\n",
    "                      label_transform=transforms.Compose([\n",
    "                          transforms.Select('emotion'),\n",
    "                          transforms.Lambda(lambda x: x + 1)\n",
    "                      ]),\n",
    "                      num_worker=4)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "491b73c2-20be-4d79-9d61-fc8f690b7563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset does not exist at path ..\\data\\seediv, generating files to path...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[PROCESS]: 100%|███████████████████████████████████████████████████████████████████████| 45/45 [02:43<00:00,  3.62s/it]\n",
      "[POST-PROCESS]:   0%|                                                                        | 0/37575 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Data(edge_index=[2, 281], x=[62, 800], edge_weight=[281]), 1)\n",
      "CPU times: total: 1.03 s\n",
      "Wall time: 3min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = SEEDIVDataset(io_path=os.path.join(DATA_DIR, \"seediv\"),\n",
    "                      root_path=os.path.join(DATA_DIR, \"SEED_IV\", 'eeg_raw_data'),\n",
    "                      online_transform=transforms.Compose([\n",
    "                          ToG(SEED_IV_ADJACENCY_MATRIX)\n",
    "                      ]),\n",
    "                      label_transform=transforms.Select('emotion'),\n",
    "                      num_worker=4)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5dffb8-575a-49b3-ab37-34fecd3759ea",
   "metadata": {},
   "source": [
    "Now we have 40+ GB of preprocessed data :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
